{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes from CSV files in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source\n",
    "https://www.nodalpoint.com/spark-dataframes-from-csv-files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\", \"test App\")\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀檔方式 1\n",
    "df1 = sqlContext.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .load(\"nyctaxisub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀檔方式 2\n",
    "df = sqlContext.read.load(\"nyctaxisub.csv\",\n",
    "                          format=\"csv\",\n",
    "                          header=\"true\",\n",
    "                          inferSchema=\"true\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_id', 'string'),\n",
       " ('_rev', 'string'),\n",
       " ('dropoff_datetime', 'timestamp'),\n",
       " ('dropoff_latitude', 'double'),\n",
       " ('dropoff_longitude', 'double'),\n",
       " ('hack_license', 'string'),\n",
       " ('medallion', 'string'),\n",
       " ('passenger_count', 'int'),\n",
       " ('pickup_datetime', 'timestamp'),\n",
       " ('pickup_latitude', 'double'),\n",
       " ('pickup_longitude', 'double'),\n",
       " ('rate_code', 'int'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('trip_distance', 'double'),\n",
       " ('trip_time_in_secs', 'int'),\n",
       " ('vendor_id', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'string'),\n",
       " ('rev', 'string'),\n",
       " ('dropoff_datetime', 'timestamp'),\n",
       " ('dropoff_lat', 'double'),\n",
       " ('dropoff_long', 'double'),\n",
       " ('hack_license', 'string'),\n",
       " ('medallion', 'string'),\n",
       " ('passenger_count', 'int'),\n",
       " ('pickup_datetime', 'timestamp'),\n",
       " ('pickup_lat', 'double'),\n",
       " ('pickup_long', 'double'),\n",
       " ('rate_code', 'int'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('trip_distance', 'double'),\n",
       " ('trip_time_in_secs', 'int'),\n",
       " ('vendor_id', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 對欄位做型態轉換 (其實這邊不必要，因為 timestamp 的判斷是正確的) 和更名\n",
    "df = (df.withColumn(\"dropoff_datetime\", df.dropoff_datetime.cast(\"timestamp\"))\n",
    "        .withColumn(\"pickup_datetime\", df.pickup_datetime.cast(\"timestamp\"))\n",
    "        .withColumnRenamed(\"_id\", \"id\")\n",
    "        .withColumnRenamed(\"_rev\", \"rev\")\n",
    "        .withColumnRenamed(\"dropoff_latitude\", \"dropoff_lat\")\n",
    "        .withColumnRenamed(\"dropoff_longitude\", \"dropoff_long\")\n",
    "        .withColumnRenamed(\"pickup_latitude\", \"pickup_lat\")\n",
    "        .withColumnRenamed(\"pickup_longitude\", \"pickup_long\"))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+---------+\n",
      "|summary|                  id|                 rev|      dropoff_lat|      dropoff_long|        hack_license|           medallion|   passenger_count|       pickup_lat|       pickup_long|         rate_code|store_and_fwd_flag|    trip_distance|trip_time_in_secs|vendor_id|\n",
      "+-------+--------------------+--------------------+-----------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+---------+\n",
      "|  count|              249999|              249999|           249999|            249999|              249999|              249999|            249999|           249999|            249999|            249999|            114383|           249999|           249999|   249999|\n",
      "|   mean|                null|                null|39.94324114547668|-72.56207672077255|                null|                null|1.7390429561718246|39.98826507731627|-72.57300293825476|1.0568522274089096|              null| 4.79039856159424|1319.435301741207|     null|\n",
      "| stddev|                null|                null| 12.6067529902577|11.520675258107435|                null|                null|1.4045588189729372| 5.52002787901459|10.065209043411434|0.3060663107564138|              null|4.248825315458567|672.1459709548136|     null|\n",
      "|    min|0024b4301e07225ee...|1-00000bb400da680...|       -3481.1343|        -1814.2775|0002555BBE359440D...|00005007A9F30E289...|                 0|              0.0|        -98.150002|                 0|                 N|              0.0|              751|      CMT|\n",
      "|    max|fff43e5eb5662eecf...|1-ffffa358cd2bc5d...|        404.95761|            2084.3|FFFC8985B6B37B60A...|FFFECF75AB6CC4FF9...|                 6|        73.989571|               0.0|                 6|                 Y|             86.3|            10680|      VTS|\n",
      "+-------+--------------------+--------------------+-----------------+------------------+--------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show() # 對數值欄位做 summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summary', 'string'),\n",
       " ('id', 'string'),\n",
       " ('rev', 'string'),\n",
       " ('dropoff_lat', 'string'),\n",
       " ('dropoff_long', 'string'),\n",
       " ('hack_license', 'string'),\n",
       " ('medallion', 'string'),\n",
       " ('passenger_count', 'string'),\n",
       " ('pickup_lat', 'string'),\n",
       " ('pickup_long', 'string'),\n",
       " ('rate_code', 'string'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('trip_distance', 'string'),\n",
       " ('trip_time_in_secs', 'string'),\n",
       " ('vendor_id', 'string')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注意每個欄位的型態其實都是 string\n",
    "df.describe().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改 describe() 傳回的精度\n",
    "def prettySummary(df):\n",
    "    '''\n",
    "    Neat summary statistics of a Spark dataframe\n",
    "    Args:\n",
    "    pyspark.sql.dataframe.DataFrame (df): input dataframe\n",
    "    Returns:\n",
    "    pandas.core.frame.DataFrame: a pandas dataframe with the summary statistics of df\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    temp = df.describe().toPandas()\n",
    "    temp.iloc[1:3, 1:] = temp.iloc[1:3, 1:].convert_objects(convert_numeric=True)\n",
    "    pd.options.display.float_format = \"{:, .2f}\".format\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'convert_objects'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4ec3db3befcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprettySummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-06eda2691ea4>\u001b[0m in \u001b[0;36mprettySummary\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:, .2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'convert_objects'"
     ]
    }
   ],
   "source": [
    "prettySummary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.dropoff_lat < 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.dropoff_lat < 10).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.trip_distance == 0.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4751"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.dropoff_long > -50).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df[13] == 0.0).count() # 用欄位的數值 index 也行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4710"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 兩個以上的條件要用 & 合併且每個條件要用括號括起來\n",
    "df.filter((df.dropoff_lat < 10) & (df.dropoff_long > -50)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4710"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df.dropoff_lat < 10)\\\n",
    "  .filter(df.dropoff_long > -50)\\\n",
    "  .count() # 也可以用連續的 filter 組合在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|max(pickup_datetime)|\n",
      "+--------------------+\n",
      "| 2013-11-26 23:46:38|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(max(\"pickup_datetime\")).show() # max(), min() 也可以用在 timestamp 上面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|max(dropoff_datetime)|\n",
      "+---------------------+\n",
      "|  2013-11-26 23:59:57|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(\"dropoff_datetime\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|min(pickup_datetime)|\n",
      "+--------------------+\n",
      "| 2013-01-10 21:27:01|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(\"pickup_datetime\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|min(dropoff_datetime)|\n",
      "+---------------------+\n",
      "|  2013-01-11 00:00:00|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(\"dropoff_datetime\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|pickup_datetime    |dropoff_datetime   |\n",
      "+-------------------+-------------------+\n",
      "|2013-01-11 21:48:00|2013-01-11 22:03:00|\n",
      "|2013-01-11 04:07:00|2013-01-11 04:28:00|\n",
      "|2013-01-11 21:46:00|2013-01-11 22:02:00|\n",
      "|2013-01-11 09:44:00|2013-01-11 10:03:00|\n",
      "|2013-01-11 21:48:00|2013-01-11 22:02:00|\n",
      "+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 檢查時間 pickup_datetime 必須要比 dropoff_datetime 還早才行\n",
    "df_dates = df.select(df[\"pickup_datetime\"], df[\"dropoff_datetime\"])\n",
    "df_dates.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df_dates.withColumn(\"pickup_lst\", df_dates.pickup_datetime < df_dates.dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates.filter(~df_dates.pickup_lst).count() # 用 ~ 來表示 not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|month(dropoff_datetime)|count|\n",
      "+-----------------------+-----+\n",
      "|                      1|91075|\n",
      "|                     11|94007|\n",
      "|                      2|64917|\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(month(df.dropoff_datetime)).count().show() # 用 month() 可以取出月份的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|max(pickup_datetime)|\n",
      "+--------------------+\n",
      "| 2013-11-26 23:46:38|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select(max(\"pickup_datetime\")).show()) # show() 是用來看結果的，不會回傳任何東西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(pickup_datetime)=datetime.datetime(2013, 11, 26, 23, 46, 38))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(max(\"pickup_datetime\")).collect() # 要回傳東西的話，需要用 collect() 會回傳一個 Row 的 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.select(max(\"pickup_datetime\")).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2013, 11, 26, 23, 46, 38)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pickup = df.select(max(\"pickup_datetime\")).collect()[0][0]\n",
    "max_pickup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import *\n",
    "max_pickup < datetime(2013, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|vendor_id|count(1)|\n",
      "+---------+--------+\n",
      "|      CMT|  114387|\n",
      "|      VTS|  135612|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable(\"taxi\") # 註冊一個暫時的表格，這樣就可以直接使用 SQL query\n",
    "sqlContext.sql(\"SELECT vendor_id, COUNT(*) FROM taxi GROUP BY vendor_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(vendor_id='CMT', count(1)=114387), Row(vendor_id='VTS', count(1)=135612)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT vendor_id, COUNT(*) FROM taxi GROUP BY vendor_id\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sqlContext.sql(\"SELECT vendor_id, COUNT(*) FROM taxi GROUP BY vendor_id\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|vendor_id|count(1)|\n",
      "+---------+--------+\n",
      "|      CMT|  114387|\n",
      "|      VTS|  135612|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumnRenamed() 也可以用在 sql context\n",
    "sqlContext.sql(\"SELECT vendor_id, COUNT(*) FROM taxi GROUP BY vendor_id\").withColumnRenamed(\"_c1\", \"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
